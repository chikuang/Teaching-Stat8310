{
  "hash": "6cbffc2d3b56a1d958c4acc1f9164c98",
  "result": {
    "engine": "knitr",
    "markdown": "# Week 7 — Bayesian Decision Theory\n\nThis week introduces the **decision-theoretic foundation** of Bayesian inference.  \nWe study how posterior distributions lead naturally to optimal decisions when losses or utilities are specified, and apply the theory to point estimation and hypothesis testing.\n\n---\n\n## Learning Goals\n\nBy the end of this week, you should be able to:\n\n- Describe the Bayesian decision-theoretic framework.  \n- Define loss functions and posterior expected loss.  \n- Derive Bayes rules for common loss functions.  \n- Apply Bayesian decision principles to estimation and classification.  \n- Distinguish between point estimation, interval estimation, and decision-making contexts.\n\n---\n\n## Lecture 1 — Principles of Bayesian Decision Theory\n\n### 1.1 Motivation\n\nStatistical inference often involves making decisions under uncertainty:  \nselect an action $begin:math:text$ a $end:math:text$ based on observed data $begin:math:text$ y $end:math:text$.  \nEach action has a **loss** (or **utility**) depending on the true parameter value $begin:math:text$ \\\\theta $end:math:text$.\n\n### 1.2 The Decision-Theoretic Setup\n\n- Parameter: $begin:math:text$ \\\\theta \\\\in \\\\Theta $end:math:text$  \n- Data: $begin:math:text$ y $end:math:text$  \n- Action space: $begin:math:text$ \\\\mathcal{A} $end:math:text$  \n- Loss function: $begin:math:text$ L(a,\\\\theta) $end:math:text$  \n\nAfter observing $begin:math:text$ y $end:math:text$, the Bayesian chooses an action $begin:math:text$ a(y) $end:math:text$ minimizing **posterior expected loss**:\n$$\n\\rho(a\\mid y) = E[L(a,\\theta)\\mid y] = \\int L(a,\\theta)\\,p(\\theta\\mid y)\\,d\\theta.\n$$\n\n**Bayes rule:**  \n$$\na^*(y) = \\arg\\min_a \\rho(a\\mid y).\n$$\n\n---\n\n### 1.3 Common Loss Functions and Bayes Rules\n\n| Loss Function | Form | Bayes Action |\n|:---------------|:------|:-------------|\n| **Squared Error** | $begin:math:text$ L(a,\\\\theta)=(a-\\\\theta)^2 $end:math:text$ | Posterior mean $begin:math:text$ E[\\\\theta\\\\mid y] $end:math:text$ |\n| **Absolute Error** | $begin:math:text$ L(a,\\\\theta)=|a-\\\\theta| $end:math:text$ | Posterior median |\n| **0–1 Loss** | $begin:math:text$ L(a,\\\\theta)=\\\\mathbb{1}\\\\{a\\\\neq\\\\theta\\\\} $end:math:text$ | Posterior mode (MAP) |\n\nThese connect the **posterior mean, median, and mode** to optimal decisions under different losses.\n\n---\n\n### 1.4 Example — Estimation under Quadratic Loss\n\nSuppose $begin:math:text$ y\\\\mid\\\\theta\\\\sim N(\\\\theta,1) $end:math:text$ with prior $begin:math:text$ \\\\theta\\\\sim N(0,1) $end:math:text$.\n\nPosterior: $begin:math:text$ \\\\theta\\\\mid y \\\\sim N\\\\!\\\\left(\\\\frac{y}{2}, \\\\frac{1}{2}\\\\right) $end:math:text$.\n\nBayes estimator under squared loss:\n$$\na^*(y)=E[\\theta\\mid y]=\\frac{y}{2}.\n$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(7)\ny <- seq(-4, 4, length=100)\nbayes_est <- y/2\nplot(y, bayes_est, type=\"l\", lwd=2, col=\"steelblue\",\n     main=\"Bayes Estimator under Squared Loss\", xlab=\"y\", ylab=\"a*(y)\")\nabline(a=0, b=1, col=\"red\", lty=2)\nlegend(\"topleft\", legend=c(\"Bayes estimator\",\"MLE (a=y)\"),\n       col=c(\"steelblue\",\"red\"), lwd=2, lty=c(1,2), bty=\"n\")\n```\n\n::: {.cell-output-display}\n![](week07_files/figure-html/quad-loss-example-1.png){width=672}\n:::\n:::\n\n\nInterpretation: The Bayes rule shrinks the estimate toward zero (the prior mean), especially for small |y|.\n\n---\n\n### 1.5 Decision Rules and Risk\n\nThe **Bayes risk** is the expected loss averaged over data and parameters:\n$$\nr(a) = E[L(a(Y),\\Theta)] = \\int\\!\\!\\int L(a(y),\\theta)\\,p(y,\\theta)\\,dy\\,d\\theta.\n$$\n\nA decision rule minimizing Bayes risk across all priors is **admissible** (cannot be uniformly improved).\n\n---\n\n### 1.6 Example — Hypothesis Testing with 0–1 Loss\n\nWe test $begin:math:text$ H_0:\\\\theta\\\\le0 $end:math:text$ vs $begin:math:text$ H_1:\\\\theta>0 $end:math:text$.\n\nLoss:\n$begin:math:display$\nL(a,\\\\theta)=\n\\\\begin{cases}\n0 & \\\\text{if correct},\\\\\\\\\n1 & \\\\text{if wrong}.\n\\\\end{cases}\n$end:math:display$\n\nPosterior decision rule:\n$$\n\\text{Accept } H_1 \\text{ if } P(\\theta>0\\mid y) > 0.5.\n$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(8)\ntheta_draws <- rnorm(5000, mean=1, sd=1)\nmean(theta_draws > 0)   # posterior probability of H1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.8406\n```\n\n\n:::\n:::\n\n\n---\n\n## Lecture 2 — Applications and Extensions\n\n### 2.1 Bayesian Credible Intervals as Decision Regions\n\nFor a given loss that penalizes excluding the true parameter,  \na **credible interval** minimizing posterior expected loss corresponds to the shortest interval containing a fixed posterior probability (e.g. 95%).\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntheta_post <- rnorm(5000, mean=2, sd=1)\nquantile(theta_post, c(0.025, 0.975))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        2.5%        97.5% \n-0.004383415  4.024907476 \n```\n\n\n:::\n:::\n\n\n---\n\n### 2.2 Decision Theory for Classification\n\nFor a two-class problem with class probabilities $begin:math:text$ p_1 = P(Y=1\\\\mid x) $end:math:text$ and $begin:math:text$ p_0 = 1-p_1 $end:math:text$:  \nMinimize expected loss $begin:math:text$ L(a,y) $end:math:text$ using a **loss matrix**.\n\n| True Class | Predict 0 | Predict 1 |\n|-------------|-----------|-----------|\n| 0 | 0 | $begin:math:text$c_{10}$end:math:text$ |\n| 1 | $begin:math:text$c_{01}$end:math:text$ | 0 |\n\nBayes rule: choose class 1 if\n$$\n\\frac{p_1}{p_0} > \\frac{c_{10}}{c_{01}}.\n$$\n\nThe usual 0–1 loss corresponds to $begin:math:text$ c_{10}=c_{01}=1 $end:math:text$, threshold = 0.5.\n\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- seq(0,1,length=200)\nthreshold <- 0.5\nplot(p1, ifelse(p1>threshold,1,0), type=\"s\", col=\"steelblue\", lwd=2,\n     main=\"Bayesian Decision Boundary (Two-Class)\", xlab=\"P(Y=1|x)\", ylab=\"Decision: 1=Class1\")\nabline(v=threshold, col=\"red\", lty=2)\nlegend(\"topleft\", legend=c(\"Decision Rule\",\"Threshold 0.5\"),\n       col=c(\"steelblue\",\"red\"), lwd=2, lty=c(1,2), bty=\"n\")\n```\n\n::: {.cell-output-display}\n![](week07_files/figure-html/classification-rule-1.png){width=672}\n:::\n:::\n\n\n---\n\n### 2.3 Loss vs Utility\n\nUtility $begin:math:text$ U(a,\\\\theta) $end:math:text$ is simply the negative of loss.  \nMaximizing expected utility is equivalent to minimizing expected loss:\n$$\na^*(y) = \\arg\\max_a E[U(a,\\theta)\\mid y].\n$$\nThis framing is often used in economics and decision analysis.\n\n---\n\n### 2.4 Connection to Frequentist Estimation\n\nUnder certain priors and symmetric losses, Bayes rules coincide with frequentist estimators (e.g. posterior mean = MLE for flat priors).  \nBayesian decision theory thus **generalizes** classical estimation.\n\n---\n\n### 2.5 Example — Optimal Cutoff for a Diagnostic Test\n\nLet $begin:math:text$ \\\\theta $end:math:text$ denote disease presence (1 = disease).  \nIf false negatives cost 5× more than false positives, the optimal threshold satisfies\n$$\n\\frac{p_1}{p_0} > \\frac{1}{5} \\;\\Rightarrow\\; p_1 > 0.17.\n$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\np <- seq(0,1,length=200)\ndecision <- ifelse(p > 0.17, 1, 0)\nplot(p, decision, type=\"s\", col=\"darkorange\", lwd=2,\n     main=\"Decision Boundary with Unequal Losses\", xlab=\"Posterior P(Disease=1)\", ylab=\"Decision (1=Treat)\")\nabline(v=0.17, col=\"red\", lty=2)\nlegend(\"topleft\", legend=c(\"Decision\",\"Optimal cutoff\"), col=c(\"darkorange\",\"red\"),\n       lwd=2, lty=c(1,2), bty=\"n\")\n```\n\n::: {.cell-output-display}\n![](week07_files/figure-html/diagnostic-cutoff-1.png){width=672}\n:::\n:::\n\n\n---\n\n### 2.6 Summary of Bayesian Decision Theory\n\n| Concept | Description |\n|----------|--------------|\n| **Loss function** | Quantifies cost of wrong decisions |\n| **Posterior expected loss** | Average loss given observed data |\n| **Bayes rule** | Action minimizing posterior expected loss |\n| **Common losses** | Squared, absolute, 0–1 |\n| **Applications** | Estimation, hypothesis testing, classification, decision support |\n\n---\n\n## Homework 7\n\n1. **Conceptual**  \n   - Define loss and risk in the Bayesian framework.  \n   - What is the relationship between posterior mean, median, and mode under different losses?\n\n2. **Computational**  \n   - Simulate data from $begin:math:text$ N(\\\\theta,1) $end:math:text$ with prior $begin:math:text$ N(0,1) $end:math:text$.  \n   - Compute the Bayes estimator under squared loss and compare it with the MLE.  \n   - Repeat using absolute loss and report the posterior median.\n\n3. **Reflection**  \n   - How does changing the loss function alter your decision?  \n   - Give a real-world example where asymmetric losses are important.\n\n---\n\n## Key Takeaways\n\n| Concept | Summary |\n|----------|----------|\n| **Decision Theory** | Provides a unified framework linking inference to action. |\n| **Bayes Rule** | Minimizes posterior expected loss. |\n| **Common Losses** | Squared → mean; absolute → median; 0–1 → mode. |\n| **Applications** | Estimation, testing, classification, optimal thresholds. |\n| **Perspective** | Inference as a special case of decision-making under uncertainty. |\n\n---\n\n**Next Week:** Advanced Bayesian Computation — Hamiltonian Monte Carlo (HMC) and Variational Inference.",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}