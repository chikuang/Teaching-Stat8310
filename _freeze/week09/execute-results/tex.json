{
  "hash": "7ff65df31cc340fce3aef96efec4fbb1",
  "result": {
    "engine": "knitr",
    "markdown": "# Week 9 — Bayesian Model Averaging and Ensemble Learning\n\nThis week introduces **Bayesian Model Averaging (BMA)**, a principled framework to combine inferences from multiple Bayesian models, and contrasts it with **ensemble methods** common in machine learning.\\\nWe discuss model uncertainty, predictive averaging, and practical implementations for linear regression and classification.\n\n------------------------------------------------------------------------\n\n## Learning Goals\n\nBy the end of this week, you should be able to:\n\n-   Explain the motivation for Bayesian Model Averaging.\\\n-   Derive model-averaged predictions using posterior model probabilities.\\\n-   Compare BMA with frequentist model selection and ML ensembles.\\\n-   Implement BMA for simple regression models in R.\\\n-   Discuss advantages and limitations of Bayesian model combination.\n\n------------------------------------------------------------------------\n\n## Lecture 1 — Bayesian Model Averaging (BMA)\n\n### 1.1 Model Uncertainty\n\nModel selection often ignores uncertainty about which model is true.\\\nBMA accounts for this by averaging over all candidate models weighted by their posterior probabilities.\n\nFor models $M_1, \\ldots, M_K$: $$\np(M_k \\mid y) = \\frac{p(y \\mid M_k)\\,p(M_k)}{\\sum_{j=1}^K p(y \\mid M_j)\\,p(M_j)}.\n$$\n\nHere: - $p(y \\\\mid M_k)$ = marginal likelihood under model $M_k$.\\\n- $p(M_k)$ = prior model probability.\\\n- $p(M_k \\\\mid y)$ = posterior model probability.\n\n------------------------------------------------------------------------\n\n### 1.2 Model-Averaged Posterior and Predictions\n\n**Posterior distribution for parameter θ:** \n\n$$\np(\\theta \\mid y) = \\sum_{k=1}^K p(\\theta \\mid y, M_k)\\,p(M_k \\mid y).\n$$\n\n**Posterior predictive distribution:** \n\n$$\np(\\tilde{y} \\mid y) = \\sum_{k=1}^K p(\\tilde{y} \\mid y, M_k)\\,p(M_k \\mid y).\n$$\n\nBMA integrates out model uncertainty rather than conditioning on a single “best” model.\n\n-----------------\n\n### 1.3 Comparison with Model Selection\n\n| Approach | Key Idea | Limitation |\n|-----------------------|-----------------------|---------------------------|\n| Model Selection | Choose one best model (e.g., by AIC, WAIC, LOO) | Ignores model uncertainty |\n| Model Averaging | Combine all models weighted by posterior probability | Computationally heavier, prior sensitive |\n\n------------------------------------------------------------------------\n\n### 1.4 Example — Two Competing Linear Models\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(9)\nn <- 100\nx <- rnorm(n)\ny <- 1 + 2*x + 0.5*x^2 + rnorm(n, sd=1)\n\nm1 <- lm(y ~ x)\nm2 <- lm(y ~ x + I(x^2))\n\nlog_marglik1 <- -AIC(m1)/2\nlog_marglik2 <- -AIC(m2)/2\np_m1 <- exp(log_marglik1)\np_m2 <- exp(log_marglik2)\n\nw1 <- p_m1 / (p_m1 + p_m2)\nw2 <- p_m2 / (p_m1 + p_m2)\n\npred1 <- predict(m1)\npred2 <- predict(m2)\nbma_pred <- w1*pred1 + w2*pred2\n\nc(weights=c(M1=w1, M2=w2)[1:2])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  weights.M1   weights.M2 \n1.426496e-08 1.000000e+00 \n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(x, y, pch=19, col=\"#00000055\", main=\"Bayesian Model Averaging (Linear vs Quadratic)\",\n     xlab=\"x\", ylab=\"y\")\nxs <- seq(min(x), max(x), length.out=200)\nlines(xs, predict(m1, newdata=data.frame(x=xs)), col=\"steelblue\", lwd=2)\nlines(xs, predict(m2, newdata=data.frame(x=xs)), col=\"firebrick\", lwd=2)\nlines(xs, w1*predict(m1, newdata=data.frame(x=xs)) +\n          w2*predict(m2, newdata=data.frame(x=xs)),\n      col=\"darkgreen\", lwd=3, lty=2)\nlegend(\"topleft\", legend=c(\"Model 1 (linear)\",\"Model 2 (quadratic)\",\"BMA prediction\"),\n       col=c(\"steelblue\",\"firebrick\",\"darkgreen\"), lwd=c(2,2,3), lty=c(1,1,2), bty=\"n\")\n```\n\n::: {.cell-output-display}\n![Model-averaged predictions vs. data](week09_files/figure-pdf/bma-plot-1.pdf){fig-pos='H'}\n:::\n:::\n\n\nInterpretation: The model-averaged prediction blends the strengths of both models, weighted by their posterior support.\n\n------------------------------------------------------------------------\n\n### 1.5 Advantages of BMA\n\n-   Incorporates model uncertainty directly.\\\n-   Avoids overconfidence from single-model conditioning.\\\n-   Improves predictive performance, especially in small samples.\\\n-   Provides model weights interpretable as probabilities.\n\n------------------------------------------------------------------------\n\n### 1.6 Limitations\n\n-   Requires marginal likelihoods (often hard to compute).\\\n-   Sensitive to model priors and parameter priors.\\\n-   Computationally expensive for many models.\n\n------------------------------------------------------------------------\n\n## Lecture 2 — Bayesian Ensembles and Predictive Stacking\n\n### 2.1 Beyond BMA: Ensemble Learning\n\nMachine learning often uses **ensembles** (e.g., bagging, boosting, stacking) to improve prediction.\\\nBayesian analogues combine predictive distributions rather than point estimates.\n\n------------------------------------------------------------------------\n\n### 2.2 Predictive Stacking\n\nRather than using posterior model probabilities, stacking optimizes weights to **maximize predictive performance** under cross-validation: $$\nw^* = \\arg\\max_{w} \\sum_{i=1}^n \\log\\left(\\sum_k w_k\\, p(y_i \\mid y_{-i}, M_k)\\right),\n$$ subject to $w_k \\\\ge 0$ and $\\\\sum_k w_k = 1$.\n\nThis yields **stacking weights** that combine models for best out-of-sample prediction.\n\n------------------------------------------------------------------------\n\n### 2.3 Example — Predictive Stacking with `loo`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(brms)\nlibrary(loo)\n\nset.seed(10)\ndat <- data.frame(x = rnorm(200))\ndat$y <- 1 + 2*dat$x + 0.5*dat$x^2 + rnorm(200)\n\nm1 <- brm(y ~ x, data=dat, refresh=0)\nm2 <- brm(y ~ x + I(x^2), data=dat, refresh=0)\n\nloo1 <- loo(m1)\nloo2 <- loo(m2)\n\n# Stacking weights based on LOO predictive densities\nw_stack <- loo_model_weights(list(m1,m2), method=\"stacking\")\nw_pseudo <- loo_model_weights(list(m1,m2), method=\"pseudobma\")\n\nw_stack\nw_pseudo\n```\n:::\n\n\nInterpretation:\\\n- *Stacking weights* directly optimize predictive log-likelihood.\\\n- *Pseudo-BMA* provides a simpler (WAIC/LOO-based) approximation.\n\n------------------------------------------------------------------------\n\n### 2.4 Comparison: BMA vs Stacking\n\n| Feature | Bayesian Model Averaging | Predictive Stacking |\n|------------------|------------------------------|------------------------|\n| **Weights** | Posterior model probabilities | Optimized predictive weights |\n| **Goal** | Represent model uncertainty | Maximize predictive performance |\n| **Computation** | Needs marginal likelihoods | Uses cross-validation |\n| **Prior dependence** | Sensitive | Weak or none |\n| **Typical use** | Theoretical coherence | Practical prediction |\n\n------\n\n### 2.5 Ensemble Prediction Example\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(11)\nn <- 100\nx <- rnorm(n)\ny_true <- 2 + 3*x - 1.5*x^2\ny <- y_true + rnorm(n, sd=2)\n\nm1 <- lm(y ~ x)\nm2 <- lm(y ~ poly(x, 2, raw=TRUE))\n\npred_grid <- seq(min(x), max(x), length=200)\np1 <- predict(m1, newdata=data.frame(x=pred_grid))\np2 <- predict(m2, newdata=data.frame(x=pred_grid))\n\n# Ensemble weighting (ad hoc stacking weights)\nw1 <- 0.3; w2 <- 0.7\np_ens <- w1*p1 + w2*p2\n\nplot(x, y, pch=19, col=\"#00000055\", main=\"Model Ensemble Prediction\",\n     xlab=\"x\", ylab=\"y\")\nlines(pred_grid, p1, col=\"blue\", lwd=2)\nlines(pred_grid, p2, col=\"red\", lwd=2)\nlines(pred_grid, p_ens, col=\"darkgreen\", lwd=3, lty=2)\nlegend(\"topleft\", legend=c(\"Model 1\",\"Model 2\",\"Ensemble\"),\n       col=c(\"blue\",\"red\",\"darkgreen\"), lwd=c(2,2,3), lty=c(1,1,2), bty=\"n\")\n```\n\n::: {.cell-output-display}\n![](week09_files/figure-pdf/ensemble-sim-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n### 2.6 Practical Guidance\n\n-   Use **BMA** when posterior model probabilities are available (few models, interpretable priors).\\\n-   Use **stacking or ensemble averaging** when prediction accuracy is the goal.\\\n-   Avoid double counting data — always base weights on held-out or cross-validation predictive performance.\n\n------------------------------------------------------------------------\n\n## Homework 9\n\n1.  **Conceptual**\n    -   Explain how BMA differs from model selection.\\\n    -   Why does stacking avoid prior sensitivity found in BMA?\n2.  **Computational**\n    -   Simulate data where two Bayesian regression models compete.\\\n    -   Fit both models in R (e.g., using `brms` or `lm`).\\\n    -   Compute stacking and pseudo-BMA weights using `loo_model_weights()`.\\\n    -   Compare model-averaged predictions to the true curve.\n3.  **Reflection**\n    -   Discuss when BMA and stacking might give very different results.\\\n    -   How can model averaging improve scientific interpretability?\n\n------------------------------------------------------------------------\n\n## Key Takeaways\n\n| Concept | Summary |\n|------------------------------------|------------------------------------|\n| **Bayesian Model Averaging** | Combines models weighted by posterior probabilities. |\n| **Predictive Stacking** | Chooses weights that maximize predictive accuracy via cross-validation. |\n| **Model Uncertainty** | Accounted for rather than ignored. |\n| **Practical Use** | BMA for interpretability; stacking for prediction. |\n| **Modern Tools** | `loo_model_weights()` in R provides both stacking and pseudo-BMA weights. |\n\n------------------------------------------------------------------------\n\n**Next Week:** Bayesian Nonparametrics — infinite-dimensional models such as Dirichlet processes and Gaussian processes for flexible Bayesian modeling.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}